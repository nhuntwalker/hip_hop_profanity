{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<h1 id=\"the_top\">Retrieving Hip Hop Lyrics from Rap Genius</h1>\n",
      "<strong>Author:</strong> Nicholas Hunt-Walker\n",
      "\n",
      "The goal of this notebook is to perform all that I need for reading a list of artists, downloading their whole discography from allmusic.com, and proceeding to retrieve lyrics for their songs from http://rap.genius.com.\n",
      "\n",
      "Once the lyrics are obtained, I filter the lyrics and search for the occurrence of these key words:<br />\n",
      "<strong>Education, Knowledge, Teacher, Teach, School, Science</strong>\n",
      "\n",
      "<h3>Jumps</h3>\n",
      "<ul>\n",
      "    <li>Functions and executions for AllMusic.com <a href=\"#allmusic\">here</a></li>\n",
      "    <li>The first foray into Rap Genius is <a href=\"#rapgenius_1\">here</a></li>\n",
      "    <li>Now we retrieve the lyrics <a href=\"#save_lyrics\">here</a></li>\n",
      "    <li>Finally, we process the lyrics <a href=\"#the_process\">here</a></li>\n",
      "</ul>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import commands as c\n",
      "import pandas as pd\n",
      "from pandas import DataFrame\n",
      "from pandas import Series\n",
      "import numpy as np\n",
      "import urllib2\n",
      "import json\n",
      "from bs4 import BeautifulSoup\n",
      "import os"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 731
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Read the list of rappers\n",
      "infile = \"list_of_rappers.txt\"\n",
      "\n",
      "artists = open(infile).readlines()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## The list Reece gave me was formatted as \"number\" and \"name\", so I had to\n",
      "## create a loop to just get the names from each line.\n",
      "\n",
      "artist_names = []\n",
      "\n",
      "for ii in range(len(artists)):\n",
      "    line = artists[ii].split()\n",
      "    if len(line) > 2:\n",
      "        the_name = ' '.join(line[1:])\n",
      "    else:\n",
      "        the_name = line[1]\n",
      "    \n",
      "    artist_names.append(the_name)\n",
      "    \n",
      "artist_names = list(set(artist_names))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<h3 id=\"allmusic\">Scraping AllMusic.com</h3>\n",
      "\n",
      "The following set of functions and function-executions are here to accurately scrape the AllMusic.com website for the tracklists that I want for each artist.\n",
      "\n",
      "<a href=\"#the_top\">Top</a>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def setup_the_allmusic_search(the_artist):\n",
      "    ## Setup to search the allmusic.com database for the artist page\n",
      "    ## Returns the search URL\n",
      "    url_root = \"http://www.allmusic.com/search/artists/\"\n",
      "    the_name = the_artist.replace(\" \",\"+\")\n",
      "    \n",
      "    return url_root+the_name\n",
      "\n",
      "def get_the_page(the_url):\n",
      "    ## Send the HTML request for any URL provided.\n",
      "    ## Return the HTML source for the requested page.\n",
      "\trequest = urllib2.urlopen(the_url)\n",
      "\thtmlSource = request.read()\n",
      "    \n",
      "\treturn htmlSource\n",
      "\n",
      "def get_db_top_search_result(artist_name):\n",
      "    ## Query AllMusic.com and get the top search result only.\n",
      "    ## Return the url for the artist page\n",
      "    htmlSource = get_the_page(setup_the_allmusic_search(artist_name))\n",
      "    soup = BeautifulSoup(htmlSource)\n",
      "    search_results = soup.findAll(\"li\", { \"class\" : \"artist\" })\n",
      "    top_result = search_results[0].findAll(\"div\", {\"class\" : \"name\"})\n",
      "    artist_url = top_result[0].find(\"a\").get(\"href\")\n",
      "    \n",
      "    return artist_url\n",
      "\n",
      "def get_db_discography(url):\n",
      "    ## Returns the HTML source for a given artist's page\n",
      "    the_discography_url = url+\"/discography\"\n",
      "    htmlSource = get_the_page(the_discography_url)\n",
      "    \n",
      "    return htmlSource\n",
      "\n",
      "def get_db_discography_table(htmlSource):\n",
      "    ## Take the HTML source for a discography page and \n",
      "    ## return the urls for each album, as well as the year\n",
      "    ## that it was released.\n",
      "    the_table = BeautifulSoup(htmlSource).findAll(\"table\")\n",
      "    \n",
      "    the_tds_years = the_table[0].findAll(\"td\", {\"class\" : \"year\"})\n",
      "    the_years = [data.text.strip() for data in the_tds_years]\n",
      "    \n",
      "    the_tds_albums = the_table[0].findAll(\"td\", {\"class\" : \"title\"})\n",
      "    the_album_urls = [data.find(\"a\").get(\"href\") for data in the_tds_albums]\n",
      "    \n",
      "    return the_years, the_album_urls\n",
      "\n",
      "def get_db_tracklist(the_album_urls):\n",
      "    ## Given the url for an album, this function goes to the album\n",
      "    ## page, and returns the title of every track listed for that album.\n",
      "    the_titles = []\n",
      "    for ii in range(len(the_album_urls)):\n",
      "        htmlSource = get_the_page(the_album_urls[ii])\n",
      "        the_titles_raw = BeautifulSoup(htmlSource).findAll(\"div\", {\"class\" : \"title\"})\n",
      "        the_titles.append([title.text.strip() for title in the_titles_raw])\n",
      "    \n",
      "    the_titles = np.concatenate(the_titles)\n",
      "    return the_titles"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 78
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Functions are set. Run them in a loop for every artist in the artist list.\n",
      "## Save the artist name as well as their song title in file \"artists_and_songs.txt\"\n",
      "\n",
      "fout = open('reece_results/artists_and_songs.txt', 'w')\n",
      "fout.write('Artist\\tSong\\n')\n",
      "fmt = \"%s\\t%s\\n\"\n",
      "\n",
      "total_song_list = []\n",
      "\n",
      "for ii in range(len(artist_names)):\n",
      "    search_result = get_db_top_search_result(artist_names[ii]) ## get the search result\n",
      "    ## sometimes we get errors. In the case of an Exception, call it a not-found.\n",
      "    try:\n",
      "        db_page = get_db_discography(search_result)\n",
      "        years, albums = get_db_discography_table(db_page)\n",
      "        all_the_songs = get_db_tracklist(albums)\n",
      "        total_song_list.append(all_the_songs)\n",
      "        \n",
      "        for jj in range(len(all_the_songs)):\n",
      "            fout.write(fmt % (artist_names[ii], all_the_songs[jj].encode('utf-8')))\n",
      "    except:\n",
      "        fout.write(fmt % (artist_names[ii], 'artist_not_found'))\n",
      "    \n",
      "fout.close()\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 96
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Each artist's tracklisting would be a list of song titles within the larger\n",
      "## list for all the artists. Just compress them all into one long list\n",
      "## of song titles so we can move forward.\n",
      "total_song_list = np.concatenate(total_song_list)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 97
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<h2 id=\"rapgenius_1\">From Here On, Rap Genius</h2>\n",
      "<p>Before this, the code was focused on getting the artist and song listings for all of the artists. Now that we have those, we query rap genius. Let's work with DataFrames in Pandas to keep things nice and ordered. Also, let's set up our first bit of functions.</p>\n",
      "\n",
      "<a href=\"#the_top\">Top</a>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def search_rapgenius_for_song_top_result(artist_name, song_name):\n",
      "    ## Unfortunately there's no set format for song URLs in the genius.com site,\n",
      "    ## so we need to search for the most probable search result for a given\n",
      "    ## artist/song combination.\n",
      "    \n",
      "    ## First we need to filter out a set of track names that will be ambiguous,\n",
      "    ## or otherwise unsearchable. All unsearchables will be noted as such.\n",
      "    bad_names = ['[Untitled]','[Untitled Track]','[Untitled Hidden Track]','','???',\n",
      "                 '?','DVD','[DVD]','Instrumental','Interlude','Intro','Outro',\n",
      "                 'Skit','Skit #1','Skit #2','Skit #3','Skit #4','[Silence]',\n",
      "                 'artist_not_found','[CD-Rom Track]','[CD-ROM Track]']\n",
      "    bad_contents = 'instrumental'\n",
      "    \n",
      "    if (str(song_name) != \"nan\"):\n",
      "        if ('instrumental' not in song_name.lower()) and (song_name not in bad_names):    \n",
      "            song_name = song_name.replace(\"'\",\"\")\n",
      "            song_name = song_name.replace(\" \",\"+\")\n",
      "    \n",
      "            url_string = \"curl -d 'name=%s' -d 'genre=rap' 'http://genius-api.com/api/songInfo'\" % (song_name)\n",
      "            all_results = eval(c.getoutput(url_string).split('\\n')[-1])\n",
      "\n",
      "            if len(all_results) > 1:\n",
      "                ## Now comes the great song-name replacement.\n",
      "                the_link = all_results[0]['link']\n",
      "                \n",
      "                artist_name = artist_name.lower()\n",
      "                artist_name = artist_name.replace(\".\",\"\")\n",
      "                artist_name = artist_name.replace(\"'\",\"\")\n",
      "                artist_name = artist_name.replace(\" \",\"-\")\n",
      "                artist_name = artist_name.replace(\"tupac\",\"2pac\")\n",
      "                artist_name = artist_name.replace(\"the-game\",\"game\")\n",
      "                song_name = song_name.lower()\n",
      "                song_name = song_name.replace(\"+\",\"-\")\n",
      "                song_name = song_name.replace(\"(\",\"\")\n",
      "                song_name = song_name.replace(\")\",\"\")\n",
      "                song_name = song_name.replace(\"'\",\"\")\n",
      "                song_name = song_name.replace(\".\",\"\")\n",
      "                song_name = song_name.replace(\",\",\"\")\n",
      "                song_name = song_name.replace(\"?\",\"\")\n",
      "                song_name = song_name.replace(\":\",\"\")\n",
      "                song_name = song_name.replace(\"/\",\"-\")\n",
      "                song_name = song_name.replace(\"a**\",\"ass\")\n",
      "                song_name = song_name.replace(\"f*****\",\"fuckin\")\n",
      "                song_name = song_name.replace(\"f****n\",\"fuckin\")            \n",
      "                song_name = song_name.replace(\"f*ck\",\"fuck\")\n",
      "                song_name = song_name.replace(\"f**k\",\"fuck\")\n",
      "                song_name = song_name.replace(\"f***k\",\"fuck\")\n",
      "                song_name = song_name.replace(\"f***\",\"fuck\")\n",
      "                song_name = song_name.replace(\"f*@k\",\"fuck\")\n",
      "                song_name = song_name.replace(\"f#@*\",\"fuck\")\n",
      "                song_name = song_name.replace(\"f*?#\",\"fuck\")\n",
      "                song_name = song_name.replace(\"f**ck\",\"fuck\")\n",
      "                song_name = song_name.replace(\"h**s\",\"hoes\")\n",
      "                song_name = song_name.replace(\"h***s\",\"hoes\")\n",
      "                song_name = song_name.replace(\"h**\",\"hoe\")\n",
      "                song_name = song_name.replace(\"buter\",\"butter\")\n",
      "                song_name = song_name.replace(\"b*****s\",\"bitches\")\n",
      "                song_name = song_name.replace(\"b******\",\"bitches\")\n",
      "                song_name = song_name.replace(\"b****\",\"bitch\")\n",
      "                song_name = song_name.replace(\"b***h\",\"bitch\")\n",
      "                song_name = song_name.replace(\"b*tch\",\"bitch\")\n",
      "                song_name = song_name.replace(\"b**tch\",\"bitch\")\n",
      "                song_name = song_name.replace(\"ni**a\",\"nigga\")\n",
      "                song_name = song_name.replace(\"n***a\",\"nigga\")\n",
      "                song_name = song_name.replace(\"n*gga\",\"nigga\")\n",
      "                song_name = song_name.replace(\"n**gaz\",\"niggaz\")\n",
      "                song_name = song_name.replace(\"n***az\",\"niggaz\")\n",
      "                song_name = song_name.replace(\"n****s\",\"niggas\")\n",
      "                song_name = song_name.replace(\"n****z\",\"niggaz\")\n",
      "                song_name = song_name.replace(\"n******\",\"niggaz\")\n",
      "                song_name = song_name.replace(\"s**t\",\"shit\")\n",
      "                song_name = song_name.replace(\"s***\",\"shit\")\n",
      "                song_name = song_name.replace(\"sh*t\",\"shit\")\n",
      "                song_name = song_name.replace(\"shi*t\",\"shit\")\n",
      "                song_name = song_name.replace(\"sh#t\",\"shit\")\n",
      "                song_name = song_name.replace(\"p***y\",\"pussy\")\n",
      "                song_name = song_name.replace(\"p*ssy\",\"pussy\")\n",
      "                song_name = song_name.replace(\"*****\",\"nigga\")\n",
      "                song_name = song_name.replace(\"****\",\"fuck\")\n",
      "                song_name = song_name.replace(\"***\",\"ass\")\n",
      "                song_name = song_name.replace(\"f*\",\"fuck\")\n",
      "                song_name = song_name.replace(\"d**k\",\"dick\")\n",
      "                \n",
      "                alt_link = \"http://rap.genius.com/%s-%s-lyrics\" % (artist_name, song_name)\n",
      "                \n",
      "                ## Even though I do the search, I still want to check that my search results\n",
      "                ## match what I expect for a rap genius lyrics page.\n",
      "                ## If they don't match, I just used my pre-constructed link.\n",
      "                ## This step is likely to produce links that don't work. Such is life.\n",
      "                if the_link.lower() != alt_link.lower():\n",
      "                    return alt_link.lower()\n",
      "                \n",
      "                else:\n",
      "                    return the_link\n",
      "            \n",
      "            else:\n",
      "                return \"no_search_results\"\n",
      "    \n",
      "        else:\n",
      "            return \"not_searchable\"\n",
      "        \n",
      "    else:\n",
      "        return \"not_searchable\"\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 542
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Read in the file containing artist and song names that was generated above.\n",
      "## Put it into a dataframe. Columns will simply be Artist and Song\n",
      "infile = 'reece_results/artists_and_songs.txt'\n",
      "song_df = pd.io.api.read_csv(infile, sep=\"\\t\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 157
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Save all the links to the link list, whether searchable or not.\n",
      "link_list = []\n",
      "\n",
      "for ii in range(13492, len(song_df)):\n",
      "    the_link = search_rapgenius_for_song_top_result(song_df.Artist[ii], song_df.Song[ii])\n",
      "    link_list.append(the_link)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 575
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "I had issues with the above loop taking a LONG long time, so the next few cells were made to accomodate that. What I would do is that when the loop caught a snag (or when I had to cut the loop off and head to work/home), I'd save what progress it made to \"already_found\". Then I'd start the loop again from whatever index it had left off at.\n",
      "\n",
      "Once the whole thing was done, I was so paranoid about my already-retrieved data that I did the following:\n",
      "<ol>\n",
      "    <li>Saved \"already_found\" to the variable \"jeepers\"</li>\n",
      "    <li>Made it into a straight forward list in \"creepers\"</li>\n",
      "    <li>Saved the links in \"creepers\" to the file, along with the artist name and song name</li>\n",
      "</ol>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"%i links\" % ii"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "16172 links\n"
       ]
      }
     ],
     "prompt_number": 576
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## already good up to ii = 13492\n",
      "already_found.append(link_list)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 577
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "jeepers = already_found"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 578
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "creepers = []\n",
      "for kk in range(len(jeepers)-11):\n",
      "    creepers.append(jeepers[kk])\n",
      "    \n",
      "for kk in range(len(jeepers)-11, len(jeepers)):\n",
      "    for nn in range(len(jeepers[kk])):\n",
      "        creepers.append(jeepers[kk][nn])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 585
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(creepers)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 586,
       "text": [
        "16173"
       ]
      }
     ],
     "prompt_number": 586
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fout = open(\"lyrics_links.txt\",\"w\")\n",
      "fout.write(\"ID\\tArtist\\tSong\\tLink\\n\")\n",
      "fmt = \"%i\\t%s\\t%s\\t%s\\n\"\n",
      "\n",
      "for jj in range(len(creepers)):\n",
      "    fout.write(fmt % (jj, song_df.Artist[jj], song_df.Song[jj], creepers[jj]))\n",
      "\n",
      "fout.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 587
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<h3 id=\"save_lyrics\">Here We Pull the Lyrics Pages Themselves</h3>\n",
      "We've retrieved all of the links to the lyrics pages, now let's actually get the damn lyrics and save them!\n",
      "\n",
      "<a href=\"#the_top\">Top</a>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Read in the lyrics list to a data frame\n",
      "## Column headers: Artist, Song, and Link\n",
      "infile = \"lyrics_links.txt\"\n",
      "\n",
      "lyrics_df = pd.io.api.read_csv(infile, sep=\"\\t\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 588
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_the_rapgenius_lyrics_page(the_url):\n",
      "    ## This function will return JUST the lyrics for every lyrics link given.\n",
      "    ## One of the major problems here is that we get Syntax Errors that we are incapable\n",
      "    ## of dealing with. We toss those out. This is likely the reason for most of our\n",
      "    ## attrition.\n",
      "    the_cmd = \"curl -d 'link=%s' -d 'genre=rap' 'http://genius-api.com/api/lyricsInfo'\" % the_url\n",
      "    the_json_data = c.getoutput(the_cmd)\n",
      "    \n",
      "    if (\"Server error\" in the_json_data) or ('502 Bad Gateway' in the_json_data):\n",
      "        return \"not_found\"\n",
      "    \n",
      "    the_json_data = the_json_data.replace(\"\\\\n\",'\\n')\n",
      "    the_json_data = the_json_data.replace('\\r',' ')\n",
      "    just_lyrics = the_json_data.split('{\"lyrics\"')\n",
      "    just_lyrics = '{\"lyrics\"'+just_lyrics[-1]\n",
      "    try:\n",
      "        just_lyrics = eval(just_lyrics.replace('\\n',' '))\n",
      "        if hasattr(just_lyrics, 'keys'):\n",
      "            if 'lyrics' in just_lyrics.keys():\n",
      "                return just_lyrics\n",
      "            else:\n",
      "                return \"not_found\"\n",
      "        else:\n",
      "            return \"not_found\"\n",
      "        \n",
      "    except SyntaxError:\n",
      "        return \"not_found\"\n",
      "        \n",
      "    \n",
      "def save_the_lyrics_page(the_dataframe, the_index, the_page_json):\n",
      "    ## Once of the lyrics have been obtained, save the lyrics to file.\n",
      "    if the_page_json != \"not_found\":\n",
      "        ii = the_index\n",
      "        the_artist = the_dataframe.Artist[ii].replace(' ','_')\n",
      "        the_song = the_dataframe.Song[ii].replace(' ','_')\n",
      "        the_song = the_dataframe.Song[ii].replace(\"\\\\\",'_')\n",
      "        the_song = the_dataframe.Song[ii].replace(\"/\",'_')\n",
      "        title_string = \"%s_%s_%i.txt\" % (the_artist, the_song, ii)\n",
      "        \n",
      "        the_verses = [section['verses'] for section in the_page_json['lyrics']['sections']]\n",
      "        \n",
      "        outdir = \"reece_results/lyric_files/\"\n",
      "        outfile = outdir+\"%s\" % title_string\n",
      "        \n",
      "        fout = open(outfile,'w')\n",
      "        fmt = \"%s\\n\"\n",
      "        \n",
      "        for jj in range(len(the_verses)):\n",
      "            for kk in range(len(the_verses[jj])):\n",
      "                if (len(the_verses[jj][kk]) > 0) & ('content' in the_verses[jj][kk].keys()):\n",
      "                    fout.write(fmt % the_verses[jj][kk]['content'])\n",
      "        \n",
      "        fout.close()\n",
      "    \n",
      "    else:\n",
      "        return 'Next...\\n'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 723
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# done up to 13971\n",
      "for jj in range(13971, len(lyrics_df)):\n",
      "    save_the_lyrics_page(lyrics_df, jj, get_the_rapgenius_lyrics_page(lyrics_df.Link[jj]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 729
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<h3 id=\"the_process\">Processing the Lyrics</h3>\n",
      "Now begins the hard processing work...\n",
      "\n",
      "<a href=\"#the_top\">Top</a>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Read in all of the file names\n",
      "\n",
      "indir = 'reece_results/lyric_files/'\n",
      "files = [f for f in os.listdir(indir) if f.endswith('.txt')]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 988
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def mash_it_up(the_files_list):\n",
      "    ## This function is the first in a couple whose\n",
      "    ## purpose is to get a simple count of words of interest\n",
      "    ## throughout all of the songs.\n",
      "    indir = \"reece_results/lyric_files/\"\n",
      "    bigtext = \"\"\n",
      "    \n",
      "    for ii in range(len(the_files_list)):\n",
      "        infile = indir+the_files_list[ii]\n",
      "        intext = open(infile).readlines()\n",
      "        if len(intext) > 0:\n",
      "            intext = ''.join(intext)       \n",
      "            bigtext += intext\n",
      "    \n",
      "    return bigtext\n",
      "\n",
      "def parse_the_lyrics_file(the_file):\n",
      "    ## Given a file name, this function will read in\n",
      "    ## the lyrics file and make them one large word block,\n",
      "    ## devoid of punctuation, with every word (hopefully)\n",
      "    ## spaced by 1 space. Easily splittable.\n",
      "\tindir = \"reece_results/lyric_files/\"\n",
      "\tinfile = indir+the_file\n",
      "\n",
      "\twords = open(infile).readlines()\n",
      "\tall_the_words = ''\n",
      "\n",
      "\tfor ii in range(len(words)):\n",
      "\t\tline = words[ii].replace('\\n',' ')\n",
      "\t\tline = line.replace('-',' ')\n",
      "\n",
      "\t\tline = line.replace(\"'\",'')\n",
      "\t\tline = line.replace('\"','')\n",
      "\t\tline = line.replace('.','')\n",
      "\t\tline = line.replace(',','')\n",
      "\t\tline = line.replace('?','')\n",
      "\t\tline = line.replace('!','')\n",
      "\t\tline = line.replace(':','')\n",
      "\t\tline = line.replace(';','')\n",
      "\t\tline = line.replace('(','')\n",
      "\t\tline = line.replace(')','')\n",
      "\t\tline = line.replace('/','')\n",
      "\t\tline = line.replace('\\\\','')\n",
      "\t\tline = line.lower()\n",
      "\t\tall_the_words += line\n",
      "\n",
      "\tall_the_words = np.array(all_the_words.split())\n",
      "\n",
      "\treturn all_the_words\n",
      "\n",
      "def word_count(text, word):\n",
      "    ## A nice little copy from some older code.\n",
      "    ## Note that the text has to be a numpy array to work.\n",
      "    ## Returns a count of the given word in the given text.\n",
      "    ## Just returns the number.\n",
      "    \n",
      "    if type(text) != np.ndarray:\n",
      "        text = np.array(text)\n",
      "        \n",
      "\tcount = len(np.where(text == word)[0])\n",
      "\treturn count\n",
      "\n",
      "def word_dict(the_lyrics, word_list=None):\n",
      "    ## Given a flat text block, this function returns a dictionary\n",
      "    ## of counts for some words. If a list of words is not given,\n",
      "    ## it will return the count of EVERY word within the given lyrics.\n",
      "    ## Note that it filters out words that are 1 character in length.\n",
      "    if word_list == None:\n",
      "        word_list = list(set(the_lyrics.lower().split()))\n",
      "        \n",
      "    the_lyrics = np.array(the_lyrics.lower().split())\n",
      "    allwords = {}\n",
      "    \n",
      "    for i in range(len(word_list)):\n",
      "        if (len(word_list[i]) > 1) & (word_count(the_lyrics, word_list[i]) > 1):\n",
      "            allwords[word_list[i]] = word_count(the_lyrics, word_list[i])\n",
      "    \n",
      "    return allwords\n",
      "\n",
      "def top_words(the_lyrics):\n",
      "    ## This function will find the top word counts, and return\n",
      "    ## a dataframe of the lyrics dictionary, sorted by counted word.\n",
      "    \n",
      "    lyrics_dict = word_dict(the_lyrics)\n",
      "    the_dataframe = DataFrame(data=lyrics_dict, columns=['Word','Count'])\n",
      "    the_dataframe = the_dataframe.sort(column=\"Count\", ascending=False)\n",
      "    \n",
      "    return the_dataframe\n",
      "    \n",
      "def unique_artists(file_list):\n",
      "    ## This function is a misnomer. It returns the indices in the original\n",
      "    ## \"song_df\" dataframe for all the song files.\n",
      "    song_indices = []\n",
      "    \n",
      "    for ii in range(len(file_list)):\n",
      "        split_this = file_list[ii].split('_')\n",
      "        get_index = eval(split_this[-1].split('.')[0])\n",
      "        song_indices.append(get_index)\n",
      "\n",
      "    return song_indices\n",
      "\n",
      "def lyric_counts(the_file_list, df_lyrics):\n",
      "    ## Returns the song author, song title, and counts for Reece's\n",
      "    ## six important words.\n",
      "    indir = \"reece_results/lyric_files/\"\n",
      "    artists = []\n",
      "    songs = []\n",
      "    science = []\n",
      "    education = [] \n",
      "    knowledge = [] \n",
      "    teacher = [] \n",
      "    teach = [] \n",
      "    school = []\n",
      "    \n",
      "    for ii in range(len(the_file_list)):\n",
      "        ## Split the file name and get the index\n",
      "        ind = eval(the_file_list[ii].split('_')[-1].split('.')[0])\n",
      "        artist = df_lyrics.Artist[ind]\n",
      "        song = df_lyrics.Song[ind]\n",
      "        artists.append(artist)\n",
      "        songs.append(song)\n",
      "        \n",
      "        ## Read the file\n",
      "        lyrics_text = open(indir+the_file_list[ii]).readlines()\n",
      "        \n",
      "        ## Filter for if file is empty\n",
      "        if len(lyrics_text) != 0:\n",
      "            text_array = np.array(' '.join(lyrics_text).lower().split())\n",
      "            the_counts = word_count(text_array, 'knowledge')\n",
      "            knowledge.append(the_counts)\n",
      "            the_counts = word_count(text_array, 'teacher')\n",
      "            teacher.append(the_counts)\n",
      "            the_counts = word_count(text_array, 'teach')\n",
      "            teach.append(the_counts)\n",
      "            the_counts = word_count(text_array, 'science')\n",
      "            science.append(the_counts)\n",
      "            the_counts = word_count(text_array, 'education')\n",
      "            education.append(the_counts)\n",
      "            the_counts = word_count(text_array, 'school')\n",
      "            school.append(the_counts)\n",
      "        \n",
      "           \n",
      "        else:\n",
      "            science.append(0)\n",
      "            education.append(0)\n",
      "            knowledge.append(0)\n",
      "            teacher.append(0)\n",
      "            teach.append(0)\n",
      "            school.append(0)\n",
      "        \n",
      "    return artists, songs, science, education, knowledge, teacher, teach, school\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 948
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bigtext = mash_it_up(files) ## big text block"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 753
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "table = word_dict(bigtext, word_list = ['science','education', 'knowledge', 'teacher', 'teach', 'school'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 782
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Counts of all 6 important words in ALL of the text\n",
      "print table"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{'school': 959, 'knowledge': 354, 'science': 164, 'teach': 409, 'education': 64, 'teacher': 132}\n"
       ]
      }
     ],
     "prompt_number": 783
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Just counting the number of times a \"nigga\" variant was used.\n",
      "print word_count(np.array(bigtext.split()), 'nigga')\n",
      "print word_count(np.array(bigtext.split()), 'niggas')\n",
      "print word_count(np.array(bigtext.split()), 'niggaz')\n",
      "print word_count(np.array(bigtext.split()), 'nigger')\n",
      "print word_count(np.array(bigtext.split()), 'niggers')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "12510\n",
        "13113"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "1"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "84"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "74"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 986
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "indices = unique_artists(files)\n",
      "artists = lyrics_df.Artist[indices]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 808
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "every_unique_word = top_words(bigtext)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 819
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "every_word = word_dict(bigtext)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 829
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import operator\n",
      "sorted_words = sorted(every_word.items(), key=operator.itemgetter(1))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 839
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Just a quick little loop to save the counts for every single word throughout\n",
      "## all of the lyric files.\n",
      "fdir = \"reece_results/\"\n",
      "fout = open(fdir+\"word_results.csv\",\"w\")\n",
      "fmt = \"%s,%i\\n\"\n",
      "for jj in range(len(sorted_words)-1,-1,-1):\n",
      "    fout.write(fmt % (sorted_words[jj][0], sorted_words[jj][1]))\n",
      "fout.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 854
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "artists, songs, science, education, knowledge, teacher, teach, school = lyric_counts(files, lyrics_df)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 949
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "newdf = DataFrame({'Artist Name':artists, 'Song Name':songs, 'science':science, 'education':education, 'knowledge':knowledge, 'teacher':teacher, 'teach':teach, 'school':school})"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 951
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Save sorted results for each word\n",
      "newdf.sort(column='science', ascending=False)[:50].to_csv('reece_results/songs_top_science.csv')\n",
      "newdf.sort(column='education', ascending=False)[:50].to_csv('reece_results/songs_top_education.csv')\n",
      "newdf.sort(column='knowledge', ascending=False)[:50].to_csv('reece_results/songs_top_knowledge.csv')\n",
      "newdf.sort(column='teacher', ascending=False)[:50].to_csv('reece_results/songs_top_teacher.csv')\n",
      "newdf.sort(column='teach', ascending=False)[:50].to_csv('reece_results/songs_top_teach.csv')\n",
      "newdf.sort(column='school', ascending=False)[:50].to_csv('reece_results/songs_top_school.csv')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 952
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Checking to see how many of my saved lyric files were empty\n",
      "the_count = 0\n",
      "for mm in range(len(files)):\n",
      "    intext = open('reece_results/lyric_files/'+files[mm]).readlines()\n",
      "    if len(intext) == 0:\n",
      "        the_count = the_count + 1\n",
      "\n",
      "print the_count\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "472\n"
       ]
      }
     ],
     "prompt_number": 971
    }
   ],
   "metadata": {}
  }
 ]
}